---
title: Data analysis code, Meta-Analyses in tDCS - Motor Learning Research 
author: Taym Alsalti
output:
  html_document:
    number_sections: true
    toc: true
    toc_depth: 3
    toc_float: true
---

**Load packages and dataset**
```{r setup, echo = FALSE}
knitr::opts_chunk$set(
	message = FALSE,
	warning = FALSE,
	include = TRUE
)
# options(scipen = 999, digits = 2)
```

```{css, echo = FALSE}
# Automatically number chunks
body {
  counter-reset: counter-rchunks;
}

div.main-container {
  padding-left: 3.5em;
}

pre.r {
  counter-increment: counter-rchunks;
  position: relative;
  overflow: visible;
}

pre.r::before {
  content: '[' counter(counter-rchunks) ']:';
  display: inline-block;
  position: absolute;
  left: -3.5em;
  color: rgb(48, 63, 159);
}
```


```{r}
library("readxl") 
library("writexl")
library("tidyverse")
library("metafor")
df <- read_excel("data_thesis/Data_sheet_ps_ma1.xlsx")
```

If you want to run the code outside of the project folder and without the renv.lock file (from the [`renv`](https://rstudio.github.io/renv/articles/renv.html) package), loading the packages using the package [`groundhog`](https://groundhogr.com/) would ensure the code's long term reproducibility:
```{r}
# install.packages("groundhog")
# library(groundhog)
# pkgs <- c("readxl","writexl", "tidyverse", "metafor")
# date = "2021-09-10"
# groundhog.library(pkgs, date)
```


# Meta-analysis 1

## Reproducibility 
Note that most of the code in this section was adapted from [Maassen et al. (2020)](https://doi.org/10.1371/journal.pone.0233107)'s data analysis code, available [here](https://github.com/emaassen/paper-effectsizes/tree/master/code).

### Data wrangling - before double checking data extraction
#### Add a column specifying availablity of Ms and SDs
This facilitates automating the process of using the SMDs as reported in the meta-analysis in the case of primary studies for which it was impossible to reproduce the primary effect sizes due to lack of necessary data. 
```{r}
df <- df %>% 
  mutate(data_available = if_else(is.na(mc_ps.2), "no", "yes"))
```
In the case of this meta-analysis, all primary studies (PS) reported all Ms and SDs for the second time point if they reported one of them, which is why the new column is based on the mean of the control group at the second time point as an example. Will change this code if it turns out not to be the case in a future meta-analysis. 

#### Convert standard errors extracted from PS 8 to standard deviations
```{r}
# remove asterisks highlighting SEs
df[] <- lapply(df, gsub, pattern = '*', replacement = '', fixed = TRUE)
# make sds numeric
df <- df %>% mutate_at(vars(starts_with('sd')), as.numeric)
# multiply SEs by the square of the sample size (10 in both groups in PS 8)
df[11, "sdc_ps.1"] <- df[11, "sdc_ps.1"] * sqrt(10)
df[11, "sdc_ps.2"] <- df[11, "sdc_ps.2"] * sqrt(10)
df[11, "sdt_ps.1"] <- df[11, "sdt_ps.1"] * sqrt(10)
df[11, "sdt_ps.2"] <- df[11, "sdt_ps.2"] * sqrt(10)
```

### Functions for reproducing primary SMDs

#### Cohen's $d$ for a between-groups comparison
This formula is very commonly used and can be found in dozens of text books, e.g., [Hedges and Olkin (1985, p. 78-79)](https://www.sciencedirect.com/book/9780080570655/statistical-methods-for-meta-analysis):
$$d={\frac {{\bar {x}}_{1}-{\bar {x}}_{2}}{s}}$$

$$s={\sqrt {\frac {(n_{1}-1)s_{1}^{2}+(n_{2}-1)s_{2}^{2}}{n_{1}+n_{2}-2}}}$$

Where ${\bar {x}}_{1}$ is the mean of the treatment group, ${\bar {x}}_{2}$ is the mean of the control group, $s$ is the pooled standard deviation, $n_{1}$ and $n_{2}$ are the sample sizes of the treatment and control groups, respectively, and $s_{1}$ and $s_{2}$ are the standard deviations of the treatment and control groups, respectively.


```{r}
cd_between <- function(x) {
  
  cohensd <- c()  
  
  for (k in 1:nrow(x)) {
    
    nc <- as.numeric(x$nc_ps)[k]
    nt <- as.numeric(x$nt_ps)[k]
    
    mc <-  as.numeric(x$mc_ps.2)[k]
    mt <-  as.numeric(x$mt_ps.2)[k]
    sdc <- as.numeric(x$sdc_ps.2)[k]
    sdt <- as.numeric(x$sdt_ps.2)[k]
    
    
    if (df$data_available[k] == "yes") {
      d <- ((mt - mc) / sqrt((((nc - 1) * (sdc^2)) + ((nt - 1) * (sdt^2))) / (nc + nt - 2)))
    } else {
      d <- as.numeric(df$smd_ma)[k]
    }    
    

    cohensd[k] <- d
    
  }
  return(cohensd)
}
```


#### Hedges' $g$ for a between-groups comparison
Hedges' $g$ is a small sample correction of Cohen's $d$, one way to compute it can be found in [Hedges and Olkin (1985, p. 81)](https://www.sciencedirect.com/book/9780080570655/statistical-methods-for-meta-analysis):
$$d={\frac {{\bar {x}}_{1}-{\bar {x}}_{2}}{s}}={\frac {\mu_{1}-\mu_{2}}{s}}$$

$$s={\sqrt {\frac {(n_{1}-1)s_{1}^{2}+(n_{2}-1)s_{2}^{2}}{n_{1}+n_{2}-2}}}$$

$$J={1-{\frac {3}{4N-9}}}$$

$$g=J \times d$$
Where $N = n_{1}+n_{2}$

```{r}
hg_between <- function(x) {
  
  hedgesg <- c()  
  
  for (k in 1:nrow(x)) {
    
    nc <- as.numeric(x$nc_ps)[k]
    nt <- as.numeric(x$nt_ps)[k]
    n <- nc + nt
    
    mc <-  as.numeric(x$mc_ps.2)[k]
    mt <-  as.numeric(x$mt_ps.2)[k]
    sdc <- as.numeric(x$sdc_ps.2)[k]
    sdt <- as.numeric(x$sdt_ps.2)[k]
    
    d <- (mt - mc) / sqrt((((nc - 1) * (sdc^2)) + ((nt - 1) * (sdt^2))) / (nc + nt - 2))
    # the f-else function was added to the Cohen's d function later. no need for it here since 
    # this meta-analysis used Cohen's ds, as demonstrated below
    
    # transform to hedges g
    J <- 1 - (3 / ((4 * n) - 9))  
    hedgesg[k] <- J * d
  }
  return(hedgesg)
}
```

### Reproduce primary SMDs
17 primary studies were included in MA1, based on which 21 comparisons were made and thus 21 SMDs calculated. Two comparisons were made based on studies 5, 6, 7 and 14, which had three groups: anodal, cathodal, and sham tDCS in contrast to the other studies which either had one type of tDCS or combined both types into one group. Hence, effect sizes/comparison ids 5 & 6, 7 & 8, 9 & 10, and 17 & 18 are based on identical control/sham groups.
```{r}
df$smd_r_d <- cd_between(df)
df$smd_r_g <- hg_between(df)
# put relevant columns next to each other to facilitate inspection
df <- df %>% relocate(data_available, .before = smd_r_d)
df <- df %>% relocate(smd_ma, .after = smd_r_g)
df <- df %>% relocate(24:27, .after = author)
```
Enough data were available to reproduce 8 out of the 21 effect sizes: comparison ids 4,5,6, 11, 14, 16, 17, and 18. Since the calculated Cohen's ds are almost identical to the SMDs reported in the MA, these will be used for computing the pooled SMD. Before double checking correct data extraction, 4 out of the 8 reproduced primary SMDs were equal to the reported ones after rounding to the second decimal place. For comparisons 11, 16, 17, and 18, the reproduced SMD did not equal the reported one. Data extraction for these comparisons was double checked:

* For comparison 11, the reproduced SMD was the negative of the reported one, indicating the meta-analysts reversed the sign as a reduction on the specific scale used in that study means improvement (SMD No. 11 was made positive below). Thus, this primary SMD can be seen as reproducible, which brings the number of reproducible SMDs to 5.

* For comparison 16, it turns out the means and SDs of changes were extracted, not the raw means and SDs, which were not reported in the PS. These values were removed below. Thus, the number of comparisons for which enough data is available is down to 7.

* For comparisons 17 and 18, both from PS 14, I could not find any errors in my data collection. However, since A. the meta-analysis specified "FMA" as the outcome measure used to compute the primary SMD and B. PS 14 reported values on two outcomes "FMA-total" and "UL-FMA", I tried reproducing the reported primary SMDs using the "FMA-total" values after having used the "UL-FMA" with the original data extraction. Regardless of the fact that neither sets of values reproduced the original SMDs, the UL-FMA values are more likely to be the ones used the by meta-analysts as the UL-FMA has the same scale as FMA-outcome measures from other primary studies included in the meta-analysis, which is why I will use these to compute the pooled SMD.

In sum, there were enough data in the primary studies to attempt to reproduce 7 out of the 21 SMDs reported in MA1. Out of these 7 SMDs, 5 could be  reproduced using Cohen's $d$s. 

### Data wrangling - after double checking data extraction

#### Remove the Hedges' $g$s column
```{r}
df <- select(df, -"smd_r_g")
```

#### Convert SMD 11 to positive
```{r}
# Convert the reproduced SMDs to numerics
df$smd_r_d <- as.numeric(df$smd_r_d)

# Make SMD 11 positive
df[11, "smd_r_d"] <- -df[11, "smd_r_d"]
```

#### Remove the erroneous means and SDs extracted for SMD 16
```{r}
df[16, 18:21] <- NA
# change availability of data to "no" 
df[16, "data_available"] <- "no"

# replace the reproduced SMD with the SMD reported in the MA
df[16, "smd_r_d"] <-  as.numeric(df[16, "smd_ma"])
```

#### Reproduce SMDs 17 and 18 using the alternative "FMA-total" means and SDs
```{r}
#nc_ps <- c(7, 7) 
#nt_ps <- c(7, 7)
#mc_ps.2 <- c(123.1, 123.1) # "FMA-total" values
#mt_ps.2 <- c(124.7, 126.7) # "FMA-total" values
#sdc_ps.2 <- c(7.47, 7.47) # "FMA-total" values
#sdt_ps.2 <- c(6.94, 6.18) # "FMA-total" values
#smd_ma <- c(0.94, 0.24) # SMDs reported in the meta-analysis for comparison
#ps_14b <- data.frame(nc_ps, nt_ps, mc_ps.2, mt_ps.2, sdc_ps.2, sdt_ps.2, smd_ma)
#ps_14b$alternative_smd <- cd_between(ps_14b) # "alternative" as in using alternative Ms and SDs to the originally reproduced SMDs above
```

#### Round the reproduced SMDs to match reported ones
```{r}
#df$smd_r_d <- round(df$smd_r_d,digits = 2)
```

### Functions for reproducing within-study variances
#### Compute variance of Cohen's $d$ for a between-groups comparison
To compute the pooled SMD, the within-study variance for each study, $\hat\sigma_i$, must be determined. The formula used here can be found in [Hedges and Olkin (1985, p. 86)](https://www.sciencedirect.com/book/9780080570655/statistical-methods-for-meta-analysis):

$$\hat\sigma_i={\frac {n_{1}+n_{2}}{n_{1}n_{2}}}+{\frac {d^2}{2(n_{1}+n_{2})}}$$

```{r}
vd_between <- function(x) {
  
  vd <- c()  
  
  for (k in 1:nrow(x)) {
    
    nc <- as.numeric(x$nc_ps)[k]
    nt <- as.numeric(x$nt_ps)[k]
    
    d <- as.numeric(df$smd_r_d)[k]
    
    v <- ((nc + nt) / (nc*nt)) + (d^2 / (2 * (nc + nt)))
      
    vd[k] <- v
    
  }
  return(vd)
}
```


#### Compute variances of primary SMDs
```{r}
df$vd <- vd_between(df)
df <- df %>% relocate(vd, .after = smd_ma)
```
#### Confirm that the $\hat\sigma_i$s can be reproduced by already available software
```{r}
#library("MAd")

# compute ds and corresponding within study variances
#df <- compute_ds(as.numeric(nt_ps), as.numeric(mt_ps.2), as.numeric(sdt_ps.2), as.numeric(nc_ps), as.numeric(mc_ps.2), as.numeric(sdc_ps.2), df, denom = "pooled.sd")
# note that the ds are reproduced here too

# relocate to facilitate inspection
#df <- df %>% relocate(c(d, vd, var.d), .after = smd_ma)
```

At this point (07.09.21) I was reminded that, as in the case of the Cohen's $d$s themselves, the formula for computing the corresponding within-study variance wouldn't work for studies that had no control groups (cross-over trials). I contacted the authors of MA 1 on the 08.09.21 and received a reply that they used CMA to run the meta-analysis. As of 09.09.21, I'm waiting for further information.

Update 10.09.2021: I was informed by the first author of the MA that they used an [online tool](https://automeris.io/WebPlotDigitizer/) to extract means and SDs from figures when these were not reported in the primary study. This was done for the 13 RCTs that were included if they did not report means and SDs. For the 4 remaining studies (comparisons 2, 12, 13, and 21), the authors used sample sizes in combination with $t$ or $p$ values. Thus, the following sections repeat the process using an updated dataset containing data extracted from figures.
























### Load dataset & preprocess data as above
```{r}
# load updated dataset
df <- read_excel("data_thesis/Data_sheet_ps_ma1_updated.xlsx")

# add a column specifying availability of necessary data
df <- df %>% mutate(data_available = if_else(is.na(mc_ps.2), "no", "yes"))

# remove characters marking SEs, upper bounds of SE bars, or upper bounds of CIs, to convert to SDs
df[] <- lapply(df, gsub, pattern = '/', replacement = '', fixed = TRUE)
df[] <- lapply(df, gsub, pattern = '*', replacement = '', fixed = TRUE)

# make values numeric
df <- df %>% mutate_at(vars(starts_with('sd')), as.numeric)
df <- df %>% mutate_at(vars(starts_with('mt')), as.numeric)
df <- df %>% mutate_at(vars(starts_with('mc')), as.numeric)
df <- df %>% mutate_at(vars(starts_with('smd')), as.numeric)
df <- df %>% mutate_at(vars(starts_with('n')), as.numeric)
df <- df %>% mutate_at(vars(starts_with('ci')), as.numeric)

# Convert SEs to SDs
df[3, "sdc_ps.1"] <- df[3, "sdc_ps.1"] * sqrt(10)
df[3, "sdc_ps.2"] <- df[3, "sdc_ps.2"] * sqrt(10)
df[3, "sdt_ps.1"] <- df[3, "sdt_ps.1"] * sqrt(10)
df[3, "sdt_ps.2"] <- df[3, "sdt_ps.2"] * sqrt(10)

# Convert upper bounds of SE bars extracted from figures to SDs
df[1, "sdc_ps.2"] <- (df[1, "sdc_ps.2"] - df[1, "mc_ps.2"]) * sqrt(7)
df[1, "sdt_ps.2"] <-  (df[1, "sdt_ps.2"] - df[1, "mt_ps.2"]) * sqrt(7)

df[8, "sdc_ps.2"] <- (df[8, "sdc_ps.2"] - df[8, "mc_ps.2"]) * sqrt(13)
df[8, "sdt_ps.2"] <-  (df[8, "sdt_ps.2"] - df[8, "mt_ps.2"]) * sqrt(14)

df[9, "sdc_ps.2"] <- (df[9, "sdc_ps.2"] - df[9, "mc_ps.2"]) * sqrt(13)
df[9, "sdt_ps.2"] <-  (df[9, "sdt_ps.2"] - df[9, "mt_ps.2"]) * sqrt(13)

df[10, "sdc_ps.2"] <- (df[10, "sdc_ps.2"] - df[10, "mc_ps.2"]) * sqrt(7)
df[10, "sdt_ps.2"] <-  (df[10, "sdt_ps.2"] - df[10, "mt_ps.2"]) * sqrt(6)

df[11, "sdc_ps.2"] <- (df[11, "sdc_ps.2"] - df[11, "mc_ps.2"]) * sqrt(7)
df[11, "sdt_ps.2"] <-  (df[11, "sdt_ps.2"] - df[11, "mt_ps.2"]) * sqrt(5)

# Convert upper bounds of SD bars extracted from figures to SDs
df[4, "sdc_ps.2"] <- (df[4, "sdc_ps.2"] - df[4, "mc_ps.2"])
df[4, "sdt_ps.2"] <-  (df[4, "sdt_ps.2"] - df[4, "mt_ps.2"])

# Convert upper bounds of CI bars extracted from figures to SDs
df[20, "sdc_ps.2"] <- (df[20, "sdc_ps.2"] - df[20, "mc_ps.2"]) * sqrt(45) / 1.96
df[20, "sdt_ps.2"] <-  (df[20, "sdt_ps.2"] - df[20, "mt_ps.2"]) * sqrt(45) / 1.96
```

### Reproduce primary SMDs
```{r}
cd_between <- function(x) {
  
  cohensd <- c()  
  
  for (k in 1:nrow(x)) {
    
    nc <- x$nc_ps[k]
    nt <- x$nt_ps[k]
    
    mc <-  x$mc_ps.2[k]
    mt <-  x$mt_ps.2[k]
    sdc <- x$sdc_ps.2[k]
    sdt <- x$sdt_ps.2[k]

    
    
    if (df$data_available[k] == "yes") {
      d <- ((mt - mc) / sqrt((((nc - 1) * (sdc^2)) + ((nt - 1) * (sdt^2))) / (nc + nt - 2)))
    } else {
      d <- df$smd_ma[k] # fill in the SMDs as reported in the MA if they could not be calculated based on data reported in the ps
    }    
    

    cohensd[k] <- d
    
  }
  return(cohensd)
}
```
Since this function automatically fills in the reported SMD when the one of the necessary values (mean) is missing, it does so erroneously for one ps (nr. 10, SMD 13) which did not report the means and SDs but did report an SMD, see the following chunk.
```{r}
# use the function to calculate the SMDs for which enough data is available and fill in the rest with the SMDs reported in the MA
df$smd_r_d <- cd_between(df)

# replace the SMD filled in by the function with the SMD reported in the ps
df[13, "smd_r_d"] <- df[13, "smd_ps"]

# take the absolute value of all SMDs since some SMDs were calculated using negatively coded variables
df$smd_r_d <- abs(df$smd_r_d)

# Relocate to facilitate inspection

df <- df %>% relocate(data_available, .before = smd_r_d)
df <- df %>% relocate(smd_ma, .after = smd_r_d)
df <- df %>% relocate(24:26, .after = author)
```
Since the reproduced SMD 20 is implausibly large (probably because it was calculated based on means and SDs extracted from a figure representing values after adjusting for covariates and not raw means and SDs), it was replaced by the reported SMD. 
```{r}
df[20, "smd_r_d"] <- df[20, "smd_ma"]

# change availability of data to "no" 
df[20, "data_available"] <- "no"

# round the reproduced smds to facilitate comparison
df$smd_r_d_rounded <- round(df$smd_r_d,digits = 2)
df <- df %>% relocate(smd_r_d_rounded, .after = smd_ma)
```
After the second data extraction using figures, means and SDs were available for 13 out of the 21 comparisons, that is, 9 out of the 13 controlled trial studies included in the MA. No appropriate figures, test statistics, or $p$ values were found in the remaining 4 controlled trial studies or in the 4 cross-over studies that could be used in combination with sample sizes to reasonably estimate Cohen's $d$s. However, one of the cross-over trial studies reported an SMD.

Out of the 14 SMDs for which enough data were available (13 means and SDs, 1 reported SMD), 6 could be reproduced exactly after rounding to the second digit, 5 could be reasonably approximated as to allow for assuming that the deviations were due to slight variations in how values were extracted from figures, 2 could not be reproduced with larger deviations (reproduced SMD - reported SMD =~ -.76 and .03), and 1 was the reported SMD in the cross-over study (ps 13), which the meta-analysts did not use in their MA.


### Reproduce variances of the Cohen's $d$s 
```{r}
vd_between <- function(x) {
  
  vd <- c()  
  
  for (k in 1:nrow(x)) {
    
    nc <- x$nc_ps[k]
    nt <- x$nt_ps[k]
    
    d <- df$smd_r_d[k]
    d2 <- df$smd_ma[k]
    ciu <- df$ciu_ma[k]
    
    if (df$data_available[k] == "yes") {
      v <- ((nc + nt) / (nc*nt)) + (d^2 / (2 * (nc + nt)))
    } else {
      v <- ((ciu - d2) / 1.96)^2 # calculate the variances based on the CIs reported in the MA if the variances could not be calculated based on data reported in the ps
    }

    vd[k] <- v
    
  }
  return(vd)
}
```

```{r}
df$vi_r <- vd_between(df)
# compare the variances calculated based on the ps data with the ones calculated on the CIs reported in the MA
df$vi_ma <- ((df$ciu_ma - df$smd_ma)  / 1.96)^2
df <- df %>% relocate(50:51, .after = smd_ma)
```
The variances calculated based on the reproduced Cohen's $d$s and sample sizes approximated those calculated using the CIs reported in the MA in most, but not all cases. The confidence intervals must have been computed using varying formulas (which is not implausible given the variable designs of the studies included in the MA).

### Reproduce the pooled SMD
**Load the meta-analysis level dataset**
```{r}
DF <- read_excel("data_thesis/Data_sheet_ma_ma1.xlsx")

```


#### Meta-analysis using the Cohen's $d$s & the variances calculated based on the CIs reported in the MA
```{r}
rm <- rma(smd_ma, vi_ma, data = df, method = "DL") # DerSimonian-Laird is the default between-study heterogeneity estimator in the CMA software
rm
```
The reproduced PSMD is 0.0469067 larger than the one reported in the MA. The heterogeneity parameters $\tau^2$, $Q$, and $I^2$ could not be reproduced, either.

#### Meta-analysis using the Cohen's $d$s & the weights reported in the MA
```{r}
rm <- rma(smd_ma, vi_ma, weights = weights_ma, data = df, method = "DL")
rm
```
By weighing the SMDs by the weights reported in the MA instead of the within-study variances calculated based on the reported CIs, the pooled SMD could be reproduced.

#### Meta-analysis using the reproduced Cohen's $d$s & variances
```{r}
rm <- rma(smd_r_d, vi_r, data = df, method = "DL")
rm
```
The reproduced PSMD is 0.0637099 larger than the one reported in the MA. The heterogeneity parameters are considerably larger than the reported ones.

#### Meta-analysis using the SMDs reported in the MA and SEs extracted from the funnel plot in the MA
It occurred to me to extract the SEs from the figure while working on the publication bias analysis section (see below). This extraction followed the steps: 1. extract the SMDs and the corresponding SEs using Webplotdigitizer, 2. Find the SMD reported in the MA that corresponds to each SMD extracted from the figure, 3. assign each SE paired with a figure-extracted SMD to its corresponding reported SMD.

```{r}
# SES extracted from the funnel plot, correctly ordered
df$vi_ma_f <- c(0.534502924, 0.335672515, 0.450292398, 0.603508772, 0.450292398, 0.266666667, 0.264327485, 0.440935673, 0.41871345, 0.591812865, 0.649122807, 0.562573099, 0.264327485, 0.449122807, 0.528654971, 0.596491228, 0.281871345, 0.535672515, 0.458479532, 0.216374269, 0.476023392)^2
rm <- rma(smd_ma, vi_ma_f, data = df, method = "DL")
rm
```
These results (including the heterogeneity parameters) correspond very closely to the reported ones. 




## Publication bias analysis
Besides the packages loaded above, two further packages are needed in order to conduct the publication bias analysis. The analysis in this section mostly follows the tutorial [here](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/pub-bias.html#addressing-pubbias).
```{r}
library(dmetar) # not available on CRAN: devtools::install_github("MathiasHarrer/dmetar")
library(meta)
```

### PET-PEESE
#### Put the necessary variables together
For the PET-PEESE model, the effect sizes (here SMDs), their SEs, their variances, and their inverse-variance weights, are needed.
```{r}
petpeese <- data.frame(smd_i = df$smd_ma) # smds
petpeese$v_i <- df$vi_ma_f # within-study variances (extracted from the figures)
petpeese$se_i <- sqrt(petpeese$v_i) # standard errors of SMD estimates
petpeese$w_i <- 1/petpeese$v_i # inverse variance weights
```

#### PET (precision-effect test)
```{r}
pet <- lm(smd_i ~ se_i, weights = w_i, data = petpeese)
summary(pet)
```

#### PEESE (precision-effect estimate with standard error)
```{r}
peese <- lm(smd_i ~ v_i, weights = w_i, data = petpeese)
summary(peese)
```
Both estimates indicate the presence of publication bias since they're smaller than the original.


### P-Curve
#### Create a `meta` package meta-analysis object, necessary for the `pcurve` function
```{r}
ma1 <- metagen(TE = smd_ma,
              seTE = sqrt(vi_ma_f),
              studlab = id_comparison,
              data = df,
              sm = "SMD", # type of effect size
              comb.fixed = FALSE, # not a fixed effect MA
              comb.random = TRUE, # a random effects MA
              method.tau = "DL", # DerSimonian-Laird estimator
                 )
```


#### P-Curve
```{r}
pcurve(ma1, 
       effect.estimation = TRUE,
       N = df$nt_ma + df$nc_ma, 
       dmin = 0,
       dmax = 1)
```
No indication of bias.


### Three-parameter selection model
#### Create a `metafor` package meta-analysis object, necessary for the `selmodel` function
```{r}
ma2 <- rma(yi = smd_ma,        
          sei = sqrt(vi_ma_f),
          data = df,
          method = "DL")
```

#### Fit the selection model
```{r}
selmodel(ma2,
         type = "stepfun",
         steps = 0.05)
```
No indication of bias.


## Outlier/influence diagnostics
### Leave-one-out analysis
```{r}
metainf(ma1, pooled = "random")
```
Removing SMD 8 would reduce the pooled SMD by ~ 0.05 and considerably reduce the variance.

### Some plots
#### Baujat 
```{r}
outl <- InfluenceAnalysis(ma1, random = TRUE)
plot(outl, "baujat")
```

#### Forest plot
```{r}
plot(outl, "ES")
```


SMDs 6, 7, and 8 contribute disproportionately to both the variance and the pooled SMD.

### Run meta-analysis without outliers
```{r}
update.meta(ma1, subset = -c(6, 7, 8))
```
Removing the outliers increases the pooled SMD by ~ 0.7 and eliminates between-study heterogeneity altogether.


