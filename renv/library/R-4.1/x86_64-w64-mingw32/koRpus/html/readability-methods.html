<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Measure readability</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body><div class="container">

<table width="100%" summary="page for readability {koRpus}"><tr><td>readability {koRpus}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Measure readability</h2>

<h3>Description</h3>

<p>These methods calculate several readability indices.
</p>


<h3>Usage</h3>

<pre>
readability(txt.file, ...)

## S4 method for signature 'kRp.text'
readability(
  txt.file,
  hyphen = NULL,
  index = c("ARI", "Bormuth", "Coleman", "Coleman.Liau", "Dale.Chall",
    "Danielson.Bryan", "Dickes.Steiwer", "DRP", "ELF", "Farr.Jenkins.Paterson", "Flesch",
    "Flesch.Kincaid", "FOG", "FORCAST", "Fucks", "Gutierrez", "Harris.Jacobson",
    "Linsear.Write", "LIX", "nWS", "RIX", "SMOG", "Spache", "Strain", "Traenkle.Bailer",
    "TRI", "Tuldava", "Wheeler.Smith"),
  parameters = list(),
  word.lists = list(Bormuth = NULL, Dale.Chall = NULL, Harris.Jacobson = NULL, Spache =
    NULL),
  fileEncoding = "UTF-8",
  sentc.tag = "sentc",
  nonword.class = "nonpunct",
  nonword.tag = c(),
  quiet = FALSE,
  keep.input = NULL,
  as.feature = FALSE
)

## S4 method for signature 'missing'
readability(txt.file, index)

## S4 method for signature 'kRp.readability,ANY,ANY,ANY'
x[i]

## S4 method for signature 'kRp.readability'
x[[i]]
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>txt.file</code></td>
<td>
<p>An object of class <code><a href="../help/kRp.text-class.html">kRp.text</a></code>.</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>Additional arguments for the generics.</p>
</td></tr>
<tr valign="top"><td><code>hyphen</code></td>
<td>
<p>An object of class <code><a href="../../sylly/help/kRp.hyphen-class.html">kRp.hyphen</a></code>. If <code>NULL</code>,
the text will be hyphenated automatically. All syllable handling will
be skipped automatically if it's not needed for the selected indices.</p>
</td></tr>
<tr valign="top"><td><code>index</code></td>
<td>
<p>A character vector,
indicating which indices should actually be computed. If set to <code>"all"</code>, then all available indices
will be tried (meaning all variations of all measures). If set to <code>"fast"</code>,
a subset of the default values is used that is
known to compute fast (currently,
this only excludes &quot;FOG&quot;). You can also set it to <code>"validation"</code> to get information on the current
status of validation.</p>
</td></tr>
<tr valign="top"><td><code>parameters</code></td>
<td>
<p>A list with named magic numbers,
defining the relevant parameters for each index. If none are given,
the default values are used.</p>
</td></tr>
<tr valign="top"><td><code>word.lists</code></td>
<td>
<p>A named list providing the word lists for indices which need one. If <code>NULL</code> or missing,
the indices will be
skipped and a warning is giving. Actual word lists can be provided as either a vector (or matrix or data.frame with only one column),
or as a file name, where this file must contain one word per line. Alternatively,
you can provide the number of words which are not
on the list, directly.</p>
</td></tr>
<tr valign="top"><td><code>fileEncoding</code></td>
<td>
<p>A character string defining the character encoding of the <code>word.lists</code> in case they are provided as files,
like <code>"Latin1"</code> or <code>"UTF-8"</code>.</p>
</td></tr>
<tr valign="top"><td><code>sentc.tag</code></td>
<td>
<p>A character vector with POS tags which indicate a sentence ending. The default value <code>"sentc"</code> has special meaning and
will cause the result of <code>kRp.POS.tags(lang, tags="sentc",
      list.tags=TRUE)</code> to be used.</p>
</td></tr>
<tr valign="top"><td><code>nonword.class</code></td>
<td>
<p>A character vector with word classes which should be ignored for readability analysis. The default value
<code>"nonpunct"</code> has special meaning and will cause the result of <code>kRp.POS.tags(lang,
      tags=c("punct","sentc"), list.classes=TRUE)</code>
to be used. Will only be of consequence if <code>hyphen</code> is not set!</p>
</td></tr>
<tr valign="top"><td><code>nonword.tag</code></td>
<td>
<p>A character vector with POS tags which should be ignored for readability analysis. Will only be
of consequence if <code>hyphen</code> is not set!</p>
</td></tr>
<tr valign="top"><td><code>quiet</code></td>
<td>
<p>Logical. If <code>FALSE</code>, short status messages will be shown.
<code>TRUE</code> will also suppress all potential warnings regarding the validation status of measures.</p>
</td></tr>
<tr valign="top"><td><code>keep.input</code></td>
<td>
<p>Logical. If <code>FALSE</code>,
neither the object provided by (or generated from) <code>txt.file</code> nor
<code>hyphen</code> will be kept in the output object. By default (<code>NULL</code>) they are kept if the input was not already of the needed object class
(e.g., <code>kRp.text</code>) or missing,
to allow for re-use without the need to tag or hyphenate the text again.
If <code>TRUE</code>, they are always kept. In cases where you want smaller object sizes,
set this to <code>FALSE</code> to always drop these slots.</p>
</td></tr>
<tr valign="top"><td><code>as.feature</code></td>
<td>
<p>Logical,
whether the output should be just the analysis results or the input object with
the results added as a feature. Use <code><a href="../help/corpusReadability.html">corpusReadability</a></code>
to get the results from such an aggregated object.</p>
</td></tr>
<tr valign="top"><td><code>x</code></td>
<td>
<p>An object of class <code>kRp.readability</code>.</p>
</td></tr>
<tr valign="top"><td><code>i</code></td>
<td>
<p>Defines the row selector (<code>[</code>) or the name to match (<code>[[</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the following formulae, <i>W</i> stands for the number of words,
<i>St</i> for the number of sentences, <i>C</i> for the number of
characters (usually meaning letters), <i>Sy</i> for the number of syllables,
<i>W_{3Sy}</i> for the number of words with at least three syllables,
<i>W_{&lt;3Sy}</i> for the number of words with less than three syllables, <i>W^{1Sy}</i>
for words with exactly one syllable,
<i>W_{6C}</i> for the number of words with at least six letters, and <i>W_{-WL}</i> for the number
of words which are not on a certain word list (explained where needed).
</p>

<dl>
<dt><code>"ARI"</code>:</dt><dd><p><em>Automated Readability Index</em>:
</p>
<p style="text-align: center;"><i>ARI = 0.5 * W / St + 4.71 * C / W - 21.43</i></p>

<p>If <code>parameters</code> is set to <code>ARI="NRI"</code>,
the revised parameters from the Navy Readability Indexes are used:
</p>
<p style="text-align: center;"><i>ARI_NRI = 0.4 * W / St + 6 * C / W - 27.4</i></p>

<p>If <code>parameters</code> is set to <code>ARI="simple"</code>,
the simplified formula is calculated:
</p>
<p style="text-align: center;"><i>ARI_simple = W / St + 9 * C / W</i></p>

<p>Wrapper function: <code><a href="../help/ARI.html">ARI</a></code>
</p>
</dd>
<dt><code>"Bormuth"</code>:</dt><dd><p><em>Bormuth Mean Cloze</em> &amp; Grade Placement:
</p>
<p style="text-align: center;"><i>B_MC = 0.886593 - (0.08364 * C / W) +  0.161911 * (W_-WL / W)^3</i></p>

<p style="text-align: center;"><i>- 0.21401 * (W / St) + 0.000577 * (W / St)^2</i></p>

<p style="text-align: center;"><i>- 0.000005 * (W / St)^3</i></p>

<p><strong>Note:</strong> This index needs the long Dale-Chall list of 3000 familiar (english) words to compute <i>W_-WL</i>. That is,
you must have a copy of
this word list and provide it via the <code>word.lists=list(Bormuth=&lt;your.list&gt;)</code> parameter!
</p>
<p style="text-align: center;"><i>B_GP = 4.275 + 12.881 * B_MC - (34.934 * B_MC^2) + (20.388 * B_MC^3)</i></p>

<p style="text-align: center;"><i>+ (26.194C - 2.046 C_CS^2) - (11.767 C_CS^3) - (44.285 * B_MC * C_CS)</i></p>

<p style="text-align: center;"><i>+ (97.620 * (B_MC * C_CS)^2) - (59.538 * (B_MC * C_CS)^3)</i></p>

<p>Where <i>C_CS</i> represents the cloze criterion score (35% by default).
</p>
<p>Wrapper function: <code><a href="../help/bormuth.html">bormuth</a></code>
</p>
</dd>
<dt><code>"Coleman"</code>:</dt><dd><p><em>Coleman's Readability Formulas</em>:
</p>
<p style="text-align: center;"><i>C_1 = 1.29 * (100 * W^1Sy / W) - 38.45</i></p>

<p style="text-align: center;"><i>C_2 = 1.16 * (100 * W^1Sy / W) + 1.48 * (100 * St / W) - 37.95</i></p>

<p style="text-align: center;"><i>C_3 = 1.07 * (100 * W^1Sy / W) + 1.18 * (100 * St / W) + 0.76 * (100 * W_pron / W) - 34.02</i></p>

<p style="text-align: center;"><i>C_4 = 1.04 * (100 * W^1Sy / W) + 1.06 * (100 * St / W) + 0.56 * (100 * W_pron / W) - 0.36  * (100 * W_prep / W) - 26.01</i></p>

<p>Where <i>W_pron</i> is the number of pronouns,
and <i>W_prep</i> the number of prepositions.
</p>
<p>Wrapper function: <code><a href="../help/coleman.html">coleman</a></code>
</p>
</dd>
<dt><code>"Coleman.Liau"</code>:</dt><dd><p>First estimates cloze percentage,
then calculates grade equivalent:
</p>
<p style="text-align: center;"><i>CL_ECP = 141.8401 - 0.214590 * 100 * C / W + 1.079812 * 100 * St / W</i></p>

<p style="text-align: center;"><i>CL_grade = -27.4004 * CL_ECP / 100 + 23.06395</i></p>

<p>The short form is also calculated:
</p>
<p style="text-align: center;"><i>CL_short = 5.88 * C / W - 29.6 * St / W - 15.8</i></p>

<p>Wrapper function: <code><a href="../help/coleman.liau.html">coleman.liau</a></code>
</p>
</dd>
<dt><code>"Dale.Chall"</code>:</dt><dd><p><em>New Dale-Chall Readability Formula</em>. By default the revised formula (1995) is calculated:
</p>
<p style="text-align: center;"><i>DC_new = 64 - 0.95 * 100 * W_-WL / W - 0.69 * W / St</i></p>

<p>This will result in a cloze score which is then looked up in a grading table. If <code>parameters</code> is set to <code>Dale.Chall="old"</code>,
the original formula (1948) is used:
</p>
<p style="text-align: center;"><i>DC_old = 0.1579 * 100 * W_-WL / W + 0.0496 * W / St + 3.6365</i></p>

<p>If <code>parameters</code> is set to <code>Dale.Chall="PSK"</code>,
the revised parameters by Powers-Sumner-Kearl (1958) are used:
</p>
<p style="text-align: center;"><i>DC_PSK =  0.1155 * 100 * W_-WL / W + 0.0596  * W / St + 3.2672</i></p>

<p><strong>Note:</strong> This index needs the long Dale-Chall list of 3000 familiar (english) words to compute <i>W_-WL</i>. That is,
you must have a copy of
this word list and provide it via the <code>word.lists=list(Dale.Chall=&lt;your.list&gt;)</code> parameter!
</p>
<p>Wrapper function: <code><a href="../help/dale.chall.html">dale.chall</a></code>
</p>
</dd>
<dt><code>"Danielson.Bryan"</code>:</dt><dd>
<p style="text-align: center;"><i>DB_1 = ( 1.0364 * C / Bl) + ( 0.0194 * C / St ) - 0.6059</i></p>

<p style="text-align: center;"><i>DB_2 = 131.059 - ( 10.364 * C / Bl ) - ( 0.194 * C / St )</i></p>

<p>Where <i>Bl</i> means blanks between words,
which is not really counted in this implementation, but estimated
by <i>words - 1</i>. <i>C</i> is interpreted as literally all characters.
</p>
<p>Wrapper function: <code><a href="../help/danielson.bryan.html">danielson.bryan</a></code>
</p>
</dd>
<dt><code>"Dickes.Steiwer"</code>:</dt><dd><p><em>Dickes-Steiwer Handformel</em>:
</p>
<p style="text-align: center;"><i>DS = 235.95993 - (73.021 * C / W) - (12.56438 * W / St) - (50.03293 * TTR)</i></p>

<p>Where <i>TTR</i> refers to the type-token ratio,
which will be calculated case-insensitive by default.
</p>
<p>Wrapper function: <code><a href="../help/dickes.steiwer.html">dickes.steiwer</a></code>
</p>
</dd>
<dt><code>"DRP"</code>:</dt><dd><p><em>Degrees of Reading Power</em>. Uses the Bormuth Mean Cloze Score:
</p>
<p style="text-align: center;"><i>DRP = (1 - B_MC) * 100</i></p>

<p>This formula itself has no parameters.
<strong>Note:</strong> The Bormuth index needs the long Dale-Chall list of 3000 familiar (english) words to compute <i>W_-WL</i>.
That is,
you must have a copy of this word list and provide it via the <code>word.lists=list(Bormuth=&lt;your.list&gt;)</code> parameter!
Wrapper function: <code><a href="../help/DRP.html">DRP</a></code>
</p>
</dd>
<dt><code>"ELF"</code>:</dt><dd><p>Fang's <em>Easy Listening Formula</em>:
</p>
<p style="text-align: center;"><i>ELF = W_2Sy / St</i></p>

<p>Wrapper function: <code><a href="../help/ELF.html">ELF</a></code>
</p>
</dd>
<dt><code>"Farr.Jenkins.Paterson"</code>:</dt><dd><p>A simplified version of Flesch Reading Ease:
</p>
<p style="text-align: center;"><i>FJP = -31.517 - 1.015 * W / St + 1.599 * W^1Sy / W</i></p>

<p>If <code>parameters</code> is set to <code>Farr.Jenkins.Paterson="PSK"</code>,
the revised parameters by Powers-Sumner-Kearl (1958) are used:
</p>
<p style="text-align: center;"><i>FJP_PSK = 8.4335 + 0.0923 * W / St - 0.0648 * W^1Sy / W</i></p>

<p>Wrapper function: <code><a href="../help/farr.jenkins.paterson.html">farr.jenkins.paterson</a></code>
</p>
</dd>
<dt><code>"Flesch"</code>:</dt><dd><p><em>Flesch Reading Ease</em>:
</p>
<p style="text-align: center;"><i>F_EN = 206.835 - 1.015 * W / St - 84.6 * Sy / W</i></p>

<p>Certain internationalisations of the parameters are also implemented. They can be used by setting
the <code>Flesch</code> parameter to one of the following language abbreviations.
</p>
<p><code>"de"</code> (Amstad's Verständlichkeitsindex):
</p>
<p style="text-align: center;"><i>F_DE = 180 - W / St - 58.5 * Sy / W</i></p>

<p><code>"es"</code> (Fernandez-Huerta):
</p>
<p style="text-align: center;"><i>F_ES = 206.835 - 1.02 * W / St - 60 * Sy / W</i></p>

<p><code>"es-s"</code> (Szigriszt):
</p>
<p style="text-align: center;"><i>F_ES S = 206.835 - W / St - 62.3 * Sy / W</i></p>

<p><code>"nl"</code> (Douma):
</p>
<p style="text-align: center;"><i>F_NL = 206.835 - 0.93 * W / St - 77 * Sy / W</i></p>

<p><code>"nl-b"</code> (Brouwer Leesindex):
</p>
<p style="text-align: center;"><i>F_NL B = 195 - 2 * W / St - 67 * Sy / W</i></p>

<p><code>"fr"</code> (Kandel-Moles):
</p>
<p style="text-align: center;"><i>F_FR = 209 - 1.15 * W / St - 68 * Sy / W</i></p>

<p>If <code>parameters</code> is set to <code>Flesch="PSK"</code>,
the revised parameters by Powers-Sumner-Kearl (1958) are used
to calculate a grade level:
</p>
<p style="text-align: center;"><i>F_PSK = 0.0778 * W / St + 4.55 * Sy / W - 2.2029</i></p>

<p>Wrapper function: <code><a href="../help/flesch.html">flesch</a></code>
</p>
</dd>
<dt><code>"Flesch.Kincaid"</code>:</dt><dd><p><em>Flesch-Kincaid Grade Level</em>:
</p>
<p style="text-align: center;"><i>FK = 0.39 * W / St + 11.8 * Sy / W - 15.59</i></p>

<p>Wrapper function: <code><a href="../help/flesch.kincaid.html">flesch.kincaid</a></code>
</p>
</dd>
<dt><code>"FOG"</code>:</dt><dd><p>Gunning <em>Frequency of Gobbledygook</em>:
</p>
<p style="text-align: center;"><i>FOG = 0.4 * ( W / St + 100 * W_3Sy / W )</i></p>

<p>If <code>parameters</code> is set to <code>FOG="PSK"</code>,
the revised parameters by Powers-Sumner-Kearl (1958) are used:
</p>
<p style="text-align: center;"><i>FOG_PSK = 3.0680 + ( 0.0877 * W / St ) + ( 0.0984 * 100 * W_3Sy / W )</i></p>

<p>If <code>parameters</code> is set to <code>FOG="NRI"</code>,
the new FOG count from the Navy Readability Indexes is used:
</p>
<p style="text-align: center;"><i>FOG_new = ( W_&lt;3Sy + ( 3 * W_3Sy) / ( 100 * St / W ) - 3 ) / 2</i></p>

<p>If the text was POS-tagged accordingly,
proper nouns and combinations of only easy words will not be counted as hard words,
and the syllables of verbs ending in &quot;-ed&quot;,
&quot;-es&quot; or &quot;-ing&quot; will be counted without these suffixes.
</p>
<p>Due to the need to re-hyphenate combined words after splitting them up,
this formula takes considerably longer to compute than most others.
If will be omitted if you set <code>index="fast"</code> instead of the default.
</p>
<p>Wrapper function: <code><a href="../help/FOG.html">FOG</a></code>
</p>
</dd>
<dt><code>"FORCAST"</code>:</dt><dd>
<p style="text-align: center;"><i>FORCAST = 20 - ( W^1Sy * 150 / W ) / 10</i></p>

<p>If <code>parameters</code> is set to <code>FORCAST="RGL"</code>,
the parameters for the precise reading grade level are used (see Klare, 1975, pp. 84&ndash;85):
</p>
<p style="text-align: center;"><i>FORCAST_RGL = 20.43 - 0.11 * W^1Sy * 150 / W</i></p>

<p>Wrapper function: <code><a href="../help/FORCAST.html">FORCAST</a></code>
</p>
</dd>
<dt><code>"Fucks"</code>:</dt><dd><p>Fucks' <em>Stilcharakteristik</em> (Fucks, 1955,
as cited in Briest, 1974):
</p>
<p style="text-align: center;"><i>Fucks = ( Sy / W ) * ( W / St )</i></p>

<p>This simple formula has no parameters.
</p>
<p>Wrapper function: <code><a href="../help/fucks.html">fucks</a></code>
</p>
</dd>
<dt><code>"Gutierrez"</code>:</dt><dd><p>Gutiérrez de Polini's <em>Fórmula de comprensibilidad</em> (Gutiérrez,
1972, as cited in Fernández, 2016)
for Spanish:
</p>
<p style="text-align: center;"><i>Gutierrez = 95.2 - 9.7 * C / W - 0.35 * W / St</i></p>

<p>Wrapper function: <code><a href="../help/gutierrez.html">gutierrez</a></code>
</p>
</dd>
<dt><code>"Harris.Jacobson"</code>:</dt><dd><p><em>Revised Harris-Jacobson Readability Formulas</em> (Harris &amp; Jacobson,
1974):
For primary-grade material:
</p>
<p style="text-align: center;"><i>HJ_1 = 0.094 * 100 * W_-WL / W + 0.168 *  W / St + 0.502</i></p>

<p>For material above third grade:
</p>
<p style="text-align: center;"><i>HJ_2 = 0.140 * 100 * W_-WL / W + 0.153 * W / St + 0.560</i></p>

<p>For material below forth grade:
</p>
<p style="text-align: center;"><i>HJ_3 = 0.158 * W / St + 0.055 * 100 * W_6C / W + 0.355</i></p>

<p>For material below forth grade:
</p>
<p style="text-align: center;"><i>HJ_4 = 0.070 * 100 * W_-WL / W + 0.125 * W / St + 0.037 * 100 * W_6C / W + 0.497</i></p>

<p>For material above third grade:
</p>
<p style="text-align: center;"><i>HJ_5 = 0.118 * 100 * W_-WL / W + 0.134 * W / St + 0.032 * 100 * W_6C / W + 0.424</i></p>

<p><strong>Note:</strong> This index needs the short Harris-Jacobson word list for grades 1 and 2 (english) to compute <i>W_{-WL}</i>. That is,
you must have a copy of
this word list and provide it via the <code>word.lists=list(Harris.Jacobson=&lt;your.list&gt;)</code> parameter!
</p>
<p>Wrapper function: <code><a href="../help/harris.jacobson.html">harris.jacobson</a></code>
</p>
</dd>
<dt><code>"Linsear.Write"</code> (O'Hayre, undated, see Klare, 1975, p. 85):</dt><dd>
<p style="text-align: center;"><i>LW_raw = ( 100 - 100 * W_&lt;3Sy / W + ( 3 * 100 * W_3Sy / W ) ) / ( 100 * St / W )</i></p>

<p style="text-align: center;"><i>LW(LW_raw &lt;= 20) = LW_raw - 2 / 2</i></p>

<p style="text-align: center;"><i>LW(LW_raw &gt; 20) = LW_raw / 2</i></p>

<p>Wrapper function: <code><a href="../help/linsear.write.html">linsear.write</a></code>
</p>
</dd>
<dt><code>"LIX"</code></dt><dd><p>Björnsson's <em>Läsbarhetsindex</em>. Originally proposed for Swedish texts,
calculated by:
</p>
<p style="text-align: center;"><i>LIX = W / St + (W7C * 100) / W</i></p>

<p>Texts with a LIX &lt; 25 are considered very easy, around 40 normal,
and &gt; 55 very difficult to read.
</p>
<p>Wrapper function: <code><a href="../help/LIX.html">LIX</a></code>
</p>
</dd>
<dt><code>"nWS"</code>:</dt><dd><p><em>Neue Wiener Sachtextformeln</em> (Bamberger &amp; Vanecek, 1984):
</p>
<p style="text-align: center;"><i>nWS_1 = 19.35 * W_3Sy / W + 0.1672 * W / St + 12.97 * W_6C / W - 3.27 * W^1Sy / W - 0.875</i></p>

<p style="text-align: center;"><i>nWS_2 = 20.07 * W_3Sy / W + 0.1682 * W / St + 13.73 * W_6C / W - 2.779</i></p>

<p style="text-align: center;"><i>nWS_3 = 29.63 * W_3Sy / W + 0.1905 * W / St - 1.1144</i></p>

<p style="text-align: center;"><i>nWS_4 = 27.44 * W_3Sy / W + 0.2656 * W / St - 1.693</i></p>

<p>Wrapper function: <code><a href="../help/nWS.html">nWS</a></code>
</p>
</dd>
<dt><code>"RIX"</code></dt><dd><p>Anderson's <em>Readability Index</em>. A simplified version of LIX:
</p>
<p style="text-align: center;"><i>RIX = W7C / St</i></p>

<p>Texts with a RIX &lt; 1.8 are considered very easy, around 3.7 normal,
and &gt; 7.2 very difficult to read.
</p>
<p>Wrapper function: <code><a href="../help/RIX.html">RIX</a></code>
</p>
</dd>
<dt><code>"SMOG"</code>:</dt><dd><p><em>Simple Measure of Gobbledygook</em>. By default calculates formula D by McLaughlin (1969):
</p>
<p style="text-align: center;"><i>SMOG = 1.043 * &radic;{W_3Sy * 30 / St} + 3.1291</i></p>

<p>If <code>parameters</code> is set to <code>SMOG="C"</code>, formula C will be calculated:
</p>
<p style="text-align: center;"><i>SMOG_C = 0.9986 * &radic;{W_3Sy * 30 / St + 5} + 2.8795</i></p>

<p>If <code>parameters</code> is set to <code>SMOG="simple"</code>, the simplified formula is used:
</p>
<p style="text-align: center;"><i>SMOG_simple = &radic;{W_3Sy * 30 / St} + 3</i></p>

<p>If <code>parameters</code> is set to <code>SMOG="de"</code>,
the formula adapted to German texts (&quot;Qu&quot;, Bamberger &amp; Vanecek, 1984, p. 78) is used:
</p>
<p style="text-align: center;"><i>SMOG_de = &radic;{W_3Sy *  30 / St} - 2</i></p>

<p>Wrapper function: <code><a href="../help/SMOG.html">SMOG</a></code>
</p>
</dd>
<dt><code>"Spache"</code>:</dt><dd><p><em>Spache Revised Formula (1974)</em>:
</p>
<p style="text-align: center;"><i>Spache = 0.121 * W / St + 0.082 * 100 * W_-WL / W + 0.659</i></p>

<p>If <code>parameters</code> is set to <code>Spache="old"</code>, the original parameters (Spache,
1953) are used:
</p>
<p style="text-align: center;"><i>Spache_old = 0.141 * W / St + 0.086 * 100 * W_-WL / W + 0.839</i></p>

<p><strong>Note:</strong> The revised index needs the revised Spache word list (see Klare, 1975,
p. 73), and the old index the short Dale-Chall list of
769 familiar (english) words to compute <i>W_{-WL}</i>. That is,
you must have a copy of this word list and provide it via the
<code>word.lists=list(Spache=&lt;your.list&gt;)</code> parameter!
</p>
<p>Wrapper function: <code><a href="../help/spache.html">spache</a></code>
</p>
</dd>
<dt><code>"Strain"</code>:</dt><dd><p><em>Strain Index</em>. This index was proposed in [1]:
</p>
<p style="text-align: center;"><i>S = Sy * 1 / ( St / 3 ) * 1 / 10</i></p>

<p>Wrapper function: <code><a href="../help/strain.html">strain</a></code>
</p>
</dd>
<dt><code>"Traenkle.Bailer"</code>:</dt><dd><p><em>Tränkle-Bailer Formeln</em>. These two formulas were the result of a re-examination of the ones proposed
by Dickes-Steiwer. They try to avoid the usage of the type-token ratio,
which is dependent on text length (Tränkle &amp; Bailer, 1984):
</p>
<p style="text-align: center;"><i>TB1 = 224.6814 - ( 79.8304 * C / W ) - (12.24032 * W / St ) - (1.292857 * 100 * W_prep / W )</i></p>

<p style="text-align: center;"><i>TB2 = 234.1063 - ( 96.11069 * C / W ) - ( 2.05444 * 100 * W_prep / W ) - (1.02805 * 100 * W_conj / W )</i></p>

<p>Where <i>W_{prep}</i> refers to the number of prepositions,
and <i>W_{conj}</i> to the number of conjunctions.
</p>
<p>Wrapper function: <code><a href="../help/traenkle.bailer.html">traenkle.bailer</a></code>
</p>
</dd>
<dt><code>"TRI"</code>:</dt><dd><p>Kuntzsch's <em>Text-Redundanz-Index</em>. Intended mainly for German newspaper comments.
</p>
<p style="text-align: center;"><i>TRI = ( 0.449 * W^1Sy ) - ( 2.467 * Ptn ) - ( 0.937 * Frg ) - 14.417</i></p>

<p>Where <i>Ptn</i> is the number of punctuation marks and <i>Frg</i> the number of foreign words.
</p>
<p>Wrapper function: <code><a href="../help/TRI.html">TRI</a></code>
</p>
</dd>
<dt><code>"Tuldava"</code>:</dt><dd><p>Tuldava's <em>Text Difficulty Formula</em>. Supposed to be rather independent of specific languages (Grzybek,
2010).
</p>
<p style="text-align: center;"><i>TD = Sy / W * ln( W / St )</i></p>

<p>Wrapper function: <code><a href="../help/tuldava.html">tuldava</a></code>
</p>
</dd>
<dt><code>"Wheeler.Smith"</code>:</dt><dd><p>Intended for english texts in primary grades 1&ndash;4 (Wheeler &amp; Smith,
1954):
</p>
<p style="text-align: center;"><i>WS = W / St * 10 * W_2Sy / W</i></p>

<p>If <code>parameters</code> is set to <code>Wheeler.Smith="de"</code>,
the calculation stays the same, but grade placement
is done according to Bamberger &amp; Vanecek (1984), that is for german texts.
</p>
<p>Wrapper function: <code><a href="../help/wheeler.smith.html">wheeler.smith</a></code>
</p>
</dd>
</dl>

<p>By default, if the text has to be tagged yet,
the language definition is queried by calling <code>get.kRp.env(lang=TRUE)</code> internally.
Or, if <code>txt</code> has already been tagged,
by default the language definition of that tagged object is read
and used. Set <code>force.lang=get.kRp.env(lang=TRUE)</code> or to any other valid value,
if you want to forcibly overwrite this
default behaviour,
and only then. See <code><a href="../help/kRp.POS.tags.html">kRp.POS.tags</a></code> for all supported languages.
</p>


<h3>Value</h3>

<p>Depending on <code>as.feature</code>,
either an object of class <code><a href="../help/kRp.readability-class.html">kRp.readability</a></code>,
or an object of class <code><a href="../help/kRp.text-class.html">kRp.text</a></code> with the added feature <code>readability</code> containing it.
</p>


<h3>Note</h3>

<p>To get a printout of the default parameters like they're set if no other parameters are specified,
call <code>readability(parameters="dput")</code>.
In case you want to provide different parameters,
you must provide a complete set for an index, or special parameters that are
mentioned in the index descriptions above (e.g., &quot;PSK&quot;, if appropriate).
</p>


<h3>References</h3>

<p>Anderson,
J. (1981). Analysing the readability of english and non-english texts in the classroom with Lix. In
<em>Annual Meeting of the Australian Reading Association</em>, Darwin, Australia.
</p>
<p>Anderson,
J. (1983). Lix and Rix: Variations on a little-known readability index. <em>Journal of Reading</em>, 26(6), 490&ndash;496.
</p>
<p>Bamberger, R. &amp; Vanecek,
E. (1984). <em>Lesen&ndash;Verstehen&ndash;Lernen&ndash;Schreiben</em>. Wien: Jugend und Volk.
</p>
<p>Briest, W. (1974). Kann man Verständlichkeit messen? <em>Zeitschrift für Phonetik,
Sprachwissenschaft und Kommunikationsforschung</em>, 27, 543&ndash;563.
</p>
<p>Coleman, M. &amp; Liau,
T.L. (1975). A computer readability formula designed for machine scoring, <em>Journal of Applied Psychology</em>, 60(2), 283&ndash;284.
</p>
<p>Dickes, P. &amp; Steiwer,
L. (1977). Ausarbeitung von Lesbarkeitsformeln für die deutsche Sprache.
<em>Zeitschrift für Entwicklungspsychologie und Pädagogische Psychologie</em>, 9(1),
20&ndash;28.
</p>
<p>DuBay,
W.H. (2004). <em>The Principles of Readability</em>. Costa Mesa: Impact Information.
WWW: <a href="http://www.impact-information.com/impactinfo/readability02.pdf">http://www.impact-information.com/impactinfo/readability02.pdf</a>; 22.03.2011.
</p>
<p>Farr, J.N., Jenkins, J.J. &amp; Paterson,
D.G. (1951). Simplification of Flesch Reading Ease formula. <em>Journal of Applied Psychology</em>, 35(5), 333&ndash;337.
</p>
<p>Fernández, A. M. (2016,
November 30). <em>Fórmula de comprensibilidad de Gutiérrez de Polini</em>.
<a href="https://legible.es/blog/comprensibilidad-gutierrez-de-polini/">https://legible.es/blog/comprensibilidad-gutierrez-de-polini/</a>
</p>
<p>Flesch, R. (1948). A new readability yardstick. <em>Journal of Applied Psychology</em>,
32(3), 221&ndash;233.
</p>
<p>Grzybek, P. (2010). Text difficulty and the Arens-Altmann law. In Peter Grzybek,
Emmerich Kelih, Ján Mačutek (Eds.),
<em>Text and Language. Structures &ndash; Functions &ndash; Interrelations. Quantitative Perspectives</em>. Wien: Praesens,
57&ndash;70.
</p>
<p>Harris, A.J. &amp; Jacobson,
M.D. (1974). Revised Harris-Jacobson readability formulas. In <em>18th Annual Meeting of the College Reading Association</em>, Bethesda.
</p>
<p>Klare, G.R. (1975). Assessing readability. <em>Reading Research Quarterly</em>, 10(1),
62&ndash;102.
</p>
<p>McLaughlin,
G.H. (1969). SMOG grading &ndash; A new readability formula. <em>Journal of Reading</em>, 12(8), 639&ndash;646.
</p>
<p>Powers, R.D, Sumner, W.A, &amp; Kearl,
B.E. (1958). A recalculation of four adult readability formulas, <em>Journal of Educational Psychology</em>, 49(2), 99&ndash;105.
</p>
<p>Smith, E.A. &amp; Senter,
R.J. (1967). <em>Automated readability index</em>. AMRL-TR-66-22. Wright-Paterson AFB, Ohio: Aerospace Medical Division.
</p>
<p>Spache,
G. (1953). A new readability formula for primary-grade reading materials. <em>The Elementary School Journal</em>, 53, 410&ndash;413.
</p>
<p>Tränkle, U. &amp; Bailer,
H. (1984). Kreuzvalidierung und Neuberechnung von Lesbarkeitsformeln für die deutsche Sprache.
<em>Zeitschrift für Entwicklungspsychologie und Pädagogische Psychologie</em>, 16(3),
231&ndash;244.
</p>
<p>Wheeler, L.R. &amp; Smith,
E.H. (1954). A practical readability formula for the classroom teacher in the primary grades. <em>Elementary English</em>,
31, 397&ndash;399.
</p>
<p>[1] <a href="https://strainindex.wordpress.com/2007/09/25/hello-world/">https://strainindex.wordpress.com/2007/09/25/hello-world/</a>
</p>


<h3>Examples</h3>

<pre>
# code is only run when the english language package can be loaded
if(require("koRpus.lang.en", quietly = TRUE)){
  sample_file &lt;- file.path(
    path.package("koRpus"), "examples", "corpus", "Reality_Winner.txt"
  )
  # call readability() on a tokenized text
  tokenized.obj &lt;- tokenize(
    txt=sample_file,
    lang="en"
  )
  # if you call readability() without arguments,
  # you will get its results directly
  rdb.results &lt;- readability(tokenized.obj)

  # there are [ and [[ methods for these objects
  rdb.results[["ARI"]]

  # alternatively, you can also store those results as a
  # feature in the object itself
  tokenized.obj &lt;- readability(
    tokenized.obj,
    as.feature=TRUE
  )
  # results are now part of the object
  hasFeature(tokenized.obj)
  corpusReadability(tokenized.obj)
} else {}
</pre>

<hr /><div style="text-align: center;">[Package <em>koRpus</em> version 0.13-8 <a href="00Index.html">Index</a>]</div>
</div></body></html>
